{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2577,
     "status": "ok",
     "timestamp": 1615412230919,
     "user": {
      "displayName": "Lena Herrmann",
      "photoUrl": "",
      "userId": "14614092248171651689"
     },
     "user_tz": -60
    },
    "id": "ArgOkGYmncZ4",
    "outputId": "e5d62578-5a28-4dcb-c47e-ce7b7256b963"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: face_recognition in /usr/local/lib/python3.7/dist-packages (1.3.0)\n",
      "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (19.18.0)\n",
      "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.0.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face_recognition) (1.19.5)\n",
      "Requirement already satisfied: face-recognition-models>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (0.3.0)\n"
     ]
    }
   ],
   "source": [
    "# Als aller erstes müssen wir noch eine Bibliothek installieren\n",
    "!pip install face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 421,
     "status": "ok",
     "timestamp": 1615412233633,
     "user": {
      "displayName": "Lena Herrmann",
      "photoUrl": "",
      "userId": "14614092248171651689"
     },
     "user_tz": -60
    },
    "id": "QYgxd9w-m_WD"
   },
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "import face_recognition\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 501,
     "status": "ok",
     "timestamp": 1615412236784,
     "user": {
      "displayName": "Lena Herrmann",
      "photoUrl": "",
      "userId": "14614092248171651689"
     },
     "user_tz": -60
    },
    "id": "RKNG98UFtjaF",
    "outputId": "5444c571-5d64-4d6c-83ce-f8310986cd9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# Wir machen google-drive dem Notebook bekannt, um Zugriff auf die Daten zu erhalten\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "dataset = '/content/drive/MyDrive/hackerschool/training_data' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 711,
     "status": "ok",
     "timestamp": 1615412578992,
     "user": {
      "displayName": "Lena Herrmann",
      "photoUrl": "",
      "userId": "14614092248171651689"
     },
     "user_tz": -60
    },
    "id": "qPKBxO5znPI_",
    "outputId": "2e4f3734-bccb-4e6b-9c18-01a41ee103b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/hackerschool/training_data/mette_frederiksen/mette_frederiksen020.jpg\n"
     ]
    }
   ],
   "source": [
    "# Wir laden alle Dateien aus dem Verzeichnis in ein Array\n",
    "image_paths = list(paths.list_images(dataset))\n",
    "\n",
    "# So sieht der Pfad zum ersten Bild aus\n",
    "print(image_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16337,
     "status": "ok",
     "timestamp": 1615413346579,
     "user": {
      "displayName": "Lena Herrmann",
      "photoUrl": "",
      "userId": "14614092248171651689"
     },
     "user_tz": -60
    },
    "id": "2TK116Ddu4-n",
    "outputId": "21664430-2cad-464b-f1d8-ddb93e1dc9b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Bild 1/101 wird verarbeitet\n",
      "[INFO] Bild 2/101 wird verarbeitet\n",
      "[INFO] Bild 3/101 wird verarbeitet\n",
      "[INFO] Bild 4/101 wird verarbeitet\n",
      "[INFO] Bild 5/101 wird verarbeitet\n",
      "[INFO] Bild 6/101 wird verarbeitet\n",
      "[INFO] Bild 7/101 wird verarbeitet\n",
      "[INFO] Bild 8/101 wird verarbeitet\n",
      "[INFO] Bild 9/101 wird verarbeitet\n",
      "[INFO] Bild 10/101 wird verarbeitet\n",
      "[INFO] Bild 11/101 wird verarbeitet\n",
      "[INFO] Bild 12/101 wird verarbeitet\n",
      "[INFO] Bild 13/101 wird verarbeitet\n",
      "[INFO] Bild 14/101 wird verarbeitet\n",
      "[INFO] Bild 15/101 wird verarbeitet\n",
      "[INFO] Bild 16/101 wird verarbeitet\n",
      "[INFO] Bild 17/101 wird verarbeitet\n",
      "[INFO] Bild 18/101 wird verarbeitet\n",
      "[INFO] Bild 19/101 wird verarbeitet\n",
      "[INFO] Bild 20/101 wird verarbeitet\n",
      "[INFO] Bild 21/101 wird verarbeitet\n",
      "[INFO] Bild 22/101 wird verarbeitet\n",
      "[INFO] Bild 23/101 wird verarbeitet\n",
      "[INFO] Bild 24/101 wird verarbeitet\n",
      "[INFO] Bild 25/101 wird verarbeitet\n",
      "[INFO] Bild 26/101 wird verarbeitet\n",
      "[INFO] Bild 27/101 wird verarbeitet\n",
      "[INFO] Bild 28/101 wird verarbeitet\n",
      "[INFO] Bild 29/101 wird verarbeitet\n",
      "[INFO] Bild 30/101 wird verarbeitet\n",
      "[INFO] Bild 31/101 wird verarbeitet\n",
      "[INFO] Bild 32/101 wird verarbeitet\n",
      "[INFO] Bild 33/101 wird verarbeitet\n",
      "[INFO] Bild 34/101 wird verarbeitet\n",
      "[INFO] Bild 35/101 wird verarbeitet\n",
      "[INFO] Bild 36/101 wird verarbeitet\n",
      "[INFO] Bild 37/101 wird verarbeitet\n",
      "[INFO] Bild 38/101 wird verarbeitet\n",
      "[INFO] Bild 39/101 wird verarbeitet\n",
      "[INFO] Bild 40/101 wird verarbeitet\n",
      "[INFO] Bild 41/101 wird verarbeitet\n",
      "[INFO] Bild 42/101 wird verarbeitet\n",
      "[INFO] Bild 43/101 wird verarbeitet\n",
      "[INFO] Bild 44/101 wird verarbeitet\n",
      "[INFO] Bild 45/101 wird verarbeitet\n",
      "[INFO] Bild 46/101 wird verarbeitet\n",
      "[INFO] Bild 47/101 wird verarbeitet\n",
      "[INFO] Bild 48/101 wird verarbeitet\n",
      "[INFO] Bild 49/101 wird verarbeitet\n",
      "[INFO] Bild 50/101 wird verarbeitet\n",
      "[INFO] Bild 51/101 wird verarbeitet\n",
      "[INFO] Bild 52/101 wird verarbeitet\n",
      "[INFO] Bild 53/101 wird verarbeitet\n",
      "[INFO] Bild 54/101 wird verarbeitet\n",
      "[INFO] Bild 55/101 wird verarbeitet\n",
      "[INFO] Bild 56/101 wird verarbeitet\n",
      "[INFO] Bild 57/101 wird verarbeitet\n",
      "[INFO] Bild 58/101 wird verarbeitet\n",
      "[INFO] Bild 59/101 wird verarbeitet\n",
      "[INFO] Bild 60/101 wird verarbeitet\n",
      "[INFO] Bild 61/101 wird verarbeitet\n",
      "[INFO] Bild 62/101 wird verarbeitet\n",
      "[INFO] Bild 63/101 wird verarbeitet\n",
      "[INFO] Bild 64/101 wird verarbeitet\n",
      "[INFO] Bild 65/101 wird verarbeitet\n",
      "[INFO] Bild 66/101 wird verarbeitet\n",
      "[INFO] Bild 67/101 wird verarbeitet\n",
      "[INFO] Bild 68/101 wird verarbeitet\n",
      "[INFO] Bild 69/101 wird verarbeitet\n",
      "[INFO] Bild 70/101 wird verarbeitet\n",
      "[INFO] Bild 71/101 wird verarbeitet\n",
      "[INFO] Bild 72/101 wird verarbeitet\n",
      "[INFO] Bild 73/101 wird verarbeitet\n",
      "[INFO] Bild 74/101 wird verarbeitet\n",
      "[INFO] Bild 75/101 wird verarbeitet\n",
      "[INFO] Bild 76/101 wird verarbeitet\n",
      "[INFO] Bild 77/101 wird verarbeitet\n",
      "[INFO] Bild 78/101 wird verarbeitet\n",
      "[INFO] Bild 79/101 wird verarbeitet\n",
      "[INFO] Bild 80/101 wird verarbeitet\n",
      "[INFO] Bild 81/101 wird verarbeitet\n",
      "[INFO] Bild 82/101 wird verarbeitet\n",
      "[INFO] Bild 83/101 wird verarbeitet\n",
      "[INFO] Bild 84/101 wird verarbeitet\n",
      "[INFO] Bild 85/101 wird verarbeitet\n",
      "[INFO] Bild 86/101 wird verarbeitet\n",
      "[INFO] Bild 87/101 wird verarbeitet\n",
      "[INFO] Bild 88/101 wird verarbeitet\n",
      "[INFO] Bild 89/101 wird verarbeitet\n",
      "[INFO] Bild 90/101 wird verarbeitet\n",
      "[INFO] Bild 91/101 wird verarbeitet\n",
      "[INFO] Bild 92/101 wird verarbeitet\n",
      "[INFO] Bild 93/101 wird verarbeitet\n",
      "[INFO] Bild 94/101 wird verarbeitet\n",
      "[INFO] Bild 95/101 wird verarbeitet\n",
      "[INFO] Bild 96/101 wird verarbeitet\n",
      "[INFO] Bild 97/101 wird verarbeitet\n",
      "[INFO] Bild 98/101 wird verarbeitet\n",
      "[INFO] Bild 99/101 wird verarbeitet\n",
      "[INFO] Bild 100/101 wird verarbeitet\n",
      "[INFO] Bild 101/101 wird verarbeitet\n",
      "[INFO] Das gefundene Encoding wird abgespeichert\n"
     ]
    }
   ],
   "source": [
    "# wir definieren zwei Arrays, um gefundene Gesichter und die Namen dazu zwischenzuspeichern\n",
    "knownEncodings =[]\n",
    "knownNames = []\n",
    "\n",
    "# Es wird über alle vorhandenen Bilder iteriert\n",
    "for (i, image_path) in enumerate(image_paths):\n",
    "\n",
    "  print(f'[INFO] Bild {i + 1}/{len(image_paths)} wird verarbeitet')\n",
    "\n",
    "  # wir schreiben den Namen der Person aus dem Ordnernamen in eine Variable\n",
    "  name = image_path.split(os.path.sep)[-2]\n",
    "\n",
    "  # das Bild wird eingelesen und wieder von BGR nach RGB konvertiert\n",
    "  image = cv2.imread(image_path)\n",
    "  rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "  boxes = face_recognition.face_locations(rgb_image, model='cnn')\n",
    "\n",
    "  encodings = face_recognition.face_encodings(rgb_image, boxes)\n",
    "\n",
    "  for encoding in encodings:\n",
    "    knownEncodings.append(encoding)\n",
    "    knownNames.append(name)\n",
    "  \n",
    "print(\"[INFO] Das gefundene Encoding wird abgespeichert\")\n",
    "data = {\"encodings\": knownEncodings, \"names\":knownNames}\n",
    "f = open(os.path.join(dataset, \"encodings.pickle\"), \"wb\")\n",
    "f.write(pickle.dumps(data))\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jb7WKkH7IEYe"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNlUGiL/Qa94vkvt3e8txGg",
   "collapsed_sections": [],
   "mount_file_id": "1skVc5EbyaW1WCtmVtCSY-7PSqk0dRs6p",
   "name": "module_2a_training_face_recognition.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
