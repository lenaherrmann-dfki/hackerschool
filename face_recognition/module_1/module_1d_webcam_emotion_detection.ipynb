{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"module_1d_webcam_emotion_detection.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPLUrzTZ6lP0ByFR2dyJ4YF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"zH05UOEEQUYV"},"source":["import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Flatten\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import numpy as np\n","from google.colab import output\n","import cv2 as cv\n","\n","import IPython\n","from IPython import display\n","from IPython.display import Javascript, Image\n","\n","import PIL\n","import os\n","\n","from google.colab.output import eval_js\n","import base64\n","import io\n","\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DUa4sgbwSLmB"},"source":["# Wir machen google-drive dem Notebook bekannt, um Zugriff auf die Daten zu erhalten\n","from google.colab import drive\n","drive.mount('/content/drive')\n","base_dir = '/content/drive/MyDrive/hackerschool/data'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zBMFK4xNQvmC"},"source":["# Erst wird die Struktur des Models erstellt\n","emotion_detector = Sequential()\n","\n","emotion_detector.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n","emotion_detector.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n","emotion_detector.add(MaxPooling2D(pool_size=(2, 2)))\n","emotion_detector.add(Dropout(0.25))\n","\n","emotion_detector.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n","emotion_detector.add(MaxPooling2D(pool_size=(2, 2)))\n","emotion_detector.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n","emotion_detector.add(MaxPooling2D(pool_size=(2, 2)))\n","emotion_detector.add(Dropout(0.25))\n","\n","emotion_detector.add(Flatten())\n","emotion_detector.add(Dense(1024, activation='relu'))\n","emotion_detector.add(Dropout(0.5))\n","emotion_detector.add(Dense(7, activation='softmax'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JtMp3d5BQ_AW"},"source":["# Jetzt müssen wir die Gewichte vom Model laden, damit wir es tatsächlich verwenden können\n","model_weights = os.path.join(base_dir, 'emotion-model.h5')\n","emotion_detector.load_weights(model_weights)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PRWVevxSVkaR"},"source":["# Baut einen Emotion-Detector, der das Model und den Quellcode von gestern verwendet, um Gesichter zu erkennen und die gefundenen Emotionen auf das Bild schreibt\n","\n","# Tipps:\n","# Um das Modell aufzurufen müssten ihr den richtigen Bereich aus dem Bild finden und dem Model übergeben.\n","# Bevor ihr das Model aufrufen könnt, müsst ihr das Bild in die richtige Struktur bringen\n","# \n","# Erst verkleinern\n","#\n","# roi_gray = cv.resize(roi_gray, (48,48))\n","#\n","# und dann die Form ändern\n","#\n","# image = np.expand_dims(np.expand_dims(roi_gray, axis=-1), axis=0)\n","# \n","# Das Bild muss grau sein !!!! Und auf die Größe 48x48 reduziert werden !!!\n","#\n","# Das Modell könnt ihr wie folgt verwenden:\n","#\n","# emotion = emotion_detector.predict(image)\n","#\n","# Verwendet\n","#\n","# emotion = np.argmax(emotion)\n","#\n","# So könnt ihr Text auf das Bild schreiben \n","#\n","# cv.putText(frame, emotion, (x, y), cv.FONT_HERSHEY_SIMPLEX, 0.9, (255,0,0), 5, cv.LINE_AA) \n","#\n","# um die gefundenen Emotion herauszufinden\n","# Es gibt\n","# 0 = Angst\n","# 1 = Eckel\n","# 2 = Froh\n","# 3 = Neutral\n","# 4 = Traurig\n","# 5 = Überrascht\n","# 6 = Wütend \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iP5DMyLKSaUG"},"source":["# Mit diesem Methoden-Aufruf starten wir die WebCam.\n","start_webcam()"],"execution_count":null,"outputs":[]}]}